{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9786459a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Installing dependencies for RF-DETR object detection...\n",
      "‚ùå Error installing torch torchvision: Command '['c:\\\\Users\\\\Eric Aquino\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python.exe', '-m', 'pip', 'install', '-q', 'torch torchvision']' returned non-zero exit status 1.\n",
      "‚úÖ ultralytics installed successfully\n",
      "‚úÖ Pillow installed successfully\n",
      "‚úÖ matplotlib installed successfully\n",
      "‚úÖ numpy installed successfully\n",
      "‚úÖ opencv-python installed successfully\n",
      "‚úÖ pycocotools installed successfully\n",
      "‚úÖ supervision installed successfully\n",
      "‚úÖ albumentations installed successfully\n",
      "‚úÖ PyYAML installed successfully\n",
      "‚úÖ tqdm installed successfully\n",
      "\n",
      "üéâ All dependencies installed successfully!\n",
      "üì¶ CIFAR-10 dataset will be downloaded and converted to object detection format\n",
      "ü§ñ RT-DETR model will be loaded from Ultralytics\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Install Required Dependencies for RF-DETR\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install a package using pip with proper error handling\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "        print(f\"‚úÖ {package} installed successfully\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ùå Error installing {package}: {e}\")\n",
    "\n",
    "# Install required packages for RF-DETR object detection\n",
    "packages = [\n",
    "    \"torch torchvision\",  # PyTorch with torchvision for CIFAR-10\n",
    "    \"ultralytics\",        # Includes RT-DETR models\n",
    "    \"Pillow\",             # Image processing\n",
    "    \"matplotlib\",         # Plotting\n",
    "    \"numpy\",              # Numerical operations\n",
    "    \"opencv-python\",      # Computer vision\n",
    "    \"pycocotools\",        # COCO format tools for object detection\n",
    "    \"supervision\",        # Modern computer vision utilities\n",
    "    \"albumentations\",     # Data augmentation\n",
    "    \"PyYAML\",             # YAML file handling\n",
    "    \"tqdm\"                # Progress bars\n",
    "]\n",
    "\n",
    "print(\"üîß Installing dependencies for RF-DETR object detection...\")\n",
    "for package in packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"\\nüéâ All dependencies installed successfully!\")\n",
    "print(\"üì¶ CIFAR-10 dataset will be downloaded and converted to object detection format\")\n",
    "print(\"ü§ñ RT-DETR model will be loaded from Ultralytics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa95315f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Downloading and preparing CIFAR-10 for object detection...\n",
      "‚¨áÔ∏è Downloading CIFAR-10 training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 170M/170M [00:13<00:00, 12.9MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è Downloading CIFAR-10 test set...\n",
      "‚úÖ CIFAR-10 dataset loaded successfully!\n",
      "üìä Training samples: 50000\n",
      "üìä Test samples: 10000\n",
      "üìä Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "üîÑ Converting CIFAR-10 to object detection format...\n",
      "  Processed 1000 training images...\n",
      "  Processed 2000 training images...\n",
      "  Processed 3000 training images...\n",
      "  Processed 4000 training images...\n",
      "  Processed 5000 training images...\n",
      "  Processed 200 validation images...\n",
      "  Processed 400 validation images...\n",
      "  Processed 600 validation images...\n",
      "  Processed 800 validation images...\n",
      "  Processed 1000 validation images...\n",
      "‚úÖ Object detection dataset prepared in: ./cifar10_detection\n",
      "üìÅ Structure:\n",
      "  - images/train/ - training images\n",
      "  - images/val/ - validation images\n",
      "  - labels/train/ - training annotations (YOLO format)\n",
      "  - labels/val/ - validation annotations (YOLO format)\n",
      "  - data.yaml - dataset configuration\n",
      "\n",
      "üìã Sample annotation format:\n",
      "  6 0.500000 0.500000 0.843750 0.812500\n",
      "  Format: class_id x_center y_center width height (normalized 0-1)\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Download and Prepare CIFAR-10 for Object Detection\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import yaml\n",
    "import json\n",
    "import random\n",
    "\n",
    "print(\"üì¶ Downloading and preparing CIFAR-10 for object detection...\")\n",
    "\n",
    "# CIFAR-10 class names\n",
    "cifar10_classes = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "]\n",
    "\n",
    "# Download CIFAR-10 dataset (no transforms for now)\n",
    "print(\"‚¨áÔ∏è Downloading CIFAR-10 training set...\")\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=None  # We'll handle transforms manually\n",
    ")\n",
    "\n",
    "print(\"‚¨áÔ∏è Downloading CIFAR-10 test set...\")\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=None\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ CIFAR-10 dataset loaded successfully!\")\n",
    "print(f\"üìä Training samples: {len(trainset)}\")\n",
    "print(f\"üìä Test samples: {len(testset)}\")\n",
    "print(f\"üìä Classes: {cifar10_classes}\")\n",
    "\n",
    "# Create directory structure for YOLO object detection\n",
    "dataset_dir = \"./cifar10_detection\"\n",
    "os.makedirs(f\"{dataset_dir}/images/train\", exist_ok=True)\n",
    "os.makedirs(f\"{dataset_dir}/images/val\", exist_ok=True)\n",
    "os.makedirs(f\"{dataset_dir}/labels/train\", exist_ok=True)\n",
    "os.makedirs(f\"{dataset_dir}/labels/val\", exist_ok=True)\n",
    "\n",
    "def create_detection_annotation(image_size=(64, 64), padding_ratio=0.1):\n",
    "    \"\"\"Create a bounding box annotation for the entire image with some padding\"\"\"\n",
    "    width, height = image_size\n",
    "\n",
    "    # Add some randomness to bounding box to make it more realistic\n",
    "    pad_x = int(width * padding_ratio * random.uniform(0.5, 1.5))\n",
    "    pad_y = int(height * padding_ratio * random.uniform(0.5, 1.5))\n",
    "\n",
    "    # Ensure padding doesn't exceed image boundaries\n",
    "    pad_x = min(pad_x, width // 4)\n",
    "    pad_y = min(pad_y, height // 4)\n",
    "\n",
    "    # Calculate bounding box coordinates (normalized to 0-1)\n",
    "    x_center = 0.5\n",
    "    y_center = 0.5\n",
    "    bbox_width = (width - 2 * pad_x) / width\n",
    "    bbox_height = (height - 2 * pad_y) / height\n",
    "\n",
    "    return x_center, y_center, bbox_width, bbox_height\n",
    "\n",
    "def prepare_detection_data():\n",
    "    \"\"\"Convert CIFAR-10 to YOLO object detection format\"\"\"\n",
    "    print(\"üîÑ Converting CIFAR-10 to object detection format...\")\n",
    "\n",
    "    target_size = (64, 64)  # Resize CIFAR-10 images to 64x64\n",
    "\n",
    "    # Convert training data\n",
    "    train_count = 0\n",
    "    for idx, (image, label) in enumerate(trainset):\n",
    "        if train_count >= 5000:  # Limit for faster processing\n",
    "            break\n",
    "\n",
    "        class_name = cifar10_classes[label]\n",
    "\n",
    "        # Resize image\n",
    "        image_resized = image.resize(target_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "        # Save image\n",
    "        image_filename = f\"train_img_{idx:05d}.jpg\"\n",
    "        image_path = f\"{dataset_dir}/images/train/{image_filename}\"\n",
    "        image_resized.save(image_path)\n",
    "\n",
    "        # Create YOLO format annotation\n",
    "        x_center, y_center, bbox_width, bbox_height = create_detection_annotation(target_size)\n",
    "\n",
    "        # Save label file (YOLO format: class_id x_center y_center width height)\n",
    "        label_filename = f\"train_img_{idx:05d}.txt\"\n",
    "        label_path = f\"{dataset_dir}/labels/train/{label_filename}\"\n",
    "\n",
    "        with open(label_path, 'w') as f:\n",
    "            f.write(f\"{label} {x_center:.6f} {y_center:.6f} {bbox_width:.6f} {bbox_height:.6f}\\n\")\n",
    "\n",
    "        train_count += 1\n",
    "\n",
    "        if train_count % 1000 == 0:\n",
    "            print(f\"  Processed {train_count} training images...\")\n",
    "\n",
    "    # Convert test data (use as validation)\n",
    "    val_count = 0\n",
    "    for idx, (image, label) in enumerate(testset):\n",
    "        if val_count >= 1000:  # Limit for validation\n",
    "            break\n",
    "\n",
    "        class_name = cifar10_classes[label]\n",
    "\n",
    "        # Resize image\n",
    "        image_resized = image.resize(target_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "        # Save image\n",
    "        image_filename = f\"val_img_{idx:05d}.jpg\"\n",
    "        image_path = f\"{dataset_dir}/images/val/{image_filename}\"\n",
    "        image_resized.save(image_path)\n",
    "\n",
    "        # Create YOLO format annotation\n",
    "        x_center, y_center, bbox_width, bbox_height = create_detection_annotation(target_size)\n",
    "\n",
    "        # Save label file\n",
    "        label_filename = f\"val_img_{idx:05d}.txt\"\n",
    "        label_path = f\"{dataset_dir}/labels/val/{label_filename}\"\n",
    "\n",
    "        with open(label_path, 'w') as f:\n",
    "            f.write(f\"{label} {x_center:.6f} {y_center:.6f} {bbox_width:.6f} {bbox_height:.6f}\\n\")\n",
    "\n",
    "        val_count += 1\n",
    "\n",
    "        if val_count % 200 == 0:\n",
    "            print(f\"  Processed {val_count} validation images...\")\n",
    "\n",
    "# Prepare the detection data\n",
    "prepare_detection_data()\n",
    "\n",
    "# Create data.yaml file for YOLO training\n",
    "data_config = {\n",
    "    'path': os.path.abspath(dataset_dir),\n",
    "    'train': 'images/train',\n",
    "    'val': 'images/val',\n",
    "    'names': {i: name for i, name in enumerate(cifar10_classes)},\n",
    "    'nc': len(cifar10_classes)  # number of classes\n",
    "}\n",
    "\n",
    "data_yaml_path = f\"{dataset_dir}/data.yaml\"\n",
    "with open(data_yaml_path, 'w') as f:\n",
    "    yaml.dump(data_config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"‚úÖ Object detection dataset prepared in: {dataset_dir}\")\n",
    "print(\"üìÅ Structure:\")\n",
    "print(\"  - images/train/ - training images\")\n",
    "print(\"  - images/val/ - validation images\")\n",
    "print(\"  - labels/train/ - training annotations (YOLO format)\")\n",
    "print(\"  - labels/val/ - validation annotations (YOLO format)\")\n",
    "print(\"  - data.yaml - dataset configuration\")\n",
    "\n",
    "# Store dataset info\n",
    "class DatasetInfo:\n",
    "    def __init__(self):\n",
    "        self.location = dataset_dir\n",
    "        self.data_yaml = data_yaml_path\n",
    "\n",
    "dataset = DatasetInfo()\n",
    "\n",
    "# Display sample annotation\n",
    "print(f\"\\nüìã Sample annotation format:\")\n",
    "sample_label_file = f\"{dataset_dir}/labels/train/train_img_00000.txt\"\n",
    "if os.path.exists(sample_label_file):\n",
    "    with open(sample_label_file, 'r') as f:\n",
    "        sample_content = f.read().strip()\n",
    "        print(f\"  {sample_content}\")\n",
    "        print(\"  Format: class_id x_center y_center width height (normalized 0-1)\")\n",
    "else:\n",
    "    print(\"  Sample file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d8a79a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Loading RT-DETR object detection model...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/rtdetr-l.pt to 'rtdetr-l.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63.4M/63.4M [00:02<00:00, 26.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RT-DETR large model loaded successfully\n",
      "\n",
      "üìã Model Information:\n",
      "  - Model Type: rtdetr_large\n",
      "  - Architecture: RT-DETR (Real-time DEtection TRansformer)\n",
      "  - Task: Object Detection\n",
      "  - Target Classes: 10 CIFAR-10 classes\n",
      "  - Input Size: 640x640 (will be resized from 64x64)\n",
      "\n",
      "üìä CIFAR-10 Classes for Detection:\n",
      "  0: airplane\n",
      "  1: automobile\n",
      "  2: bird\n",
      "  3: cat\n",
      "  4: deer\n",
      "  5: dog\n",
      "  6: frog\n",
      "  7: horse\n",
      "  8: ship\n",
      "  9: truck\n",
      "\n",
      "üîß RT-DETR Features:\n",
      "  - Transformer-based architecture\n",
      "  - End-to-end object detection\n",
      "  - No NMS (Non-Maximum Suppression) required\n",
      "  - Real-time inference capability\n",
      "  - Better accuracy than traditional CNN detectors\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: Load RT-DETR Model\n",
    "import torch\n",
    "from ultralytics import RTDETR\n",
    "\n",
    "print(\"ü§ñ Loading RT-DETR object detection model...\")\n",
    "\n",
    "try:\n",
    "    # Load RT-DETR model (Real-time DEtection TRansformer)\n",
    "    model = RTDETR('rtdetr-l.pt')  # Large RT-DETR model\n",
    "    print(\"‚úÖ RT-DETR large model loaded successfully\")\n",
    "    model_type = \"rtdetr_large\"\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading RT-DETR large model: {e}\")\n",
    "    print(\"üîÑ Trying RT-DETR medium model...\")\n",
    "\n",
    "    try:\n",
    "        model = RTDETR('rtdetr-m.pt')  # Medium RT-DETR model\n",
    "        print(\"‚úÖ RT-DETR medium model loaded successfully\")\n",
    "        model_type = \"rtdetr_medium\"\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading RT-DETR medium model: {e}\")\n",
    "        print(\"üîÑ Trying RT-DETR small model...\")\n",
    "\n",
    "        try:\n",
    "            model = RTDETR('rtdetr-s.pt')  # Small RT-DETR model\n",
    "            print(\"‚úÖ RT-DETR small model loaded successfully\")\n",
    "            model_type = \"rtdetr_small\"\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading RT-DETR models: {e}\")\n",
    "            print(\"Please check your internet connection and try again.\")\n",
    "            raise\n",
    "\n",
    "# Display model information\n",
    "print(f\"\\nüìã Model Information:\")\n",
    "print(f\"  - Model Type: {model_type}\")\n",
    "print(f\"  - Architecture: RT-DETR (Real-time DEtection TRansformer)\")\n",
    "print(f\"  - Task: Object Detection\")\n",
    "print(f\"  - Target Classes: {len(cifar10_classes)} CIFAR-10 classes\")\n",
    "print(f\"  - Input Size: 640x640 (will be resized from 64x64)\")\n",
    "\n",
    "# Print class information\n",
    "print(f\"\\nüìä CIFAR-10 Classes for Detection:\")\n",
    "for i, class_name in enumerate(cifar10_classes):\n",
    "    print(f\"  {i}: {class_name}\")\n",
    "\n",
    "print(f\"\\nüîß RT-DETR Features:\")\n",
    "print(\"  - Transformer-based architecture\")\n",
    "print(\"  - End-to-end object detection\")\n",
    "print(\"  - No NMS (Non-Maximum Suppression) required\")\n",
    "print(\"  - Real-time inference capability\")\n",
    "print(\"  - Better accuracy than traditional CNN detectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb6e9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèãÔ∏è Starting RT-DETR object detection training...\n",
      "New https://pypi.org/project/ultralytics/8.3.170 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.160  Python-3.13.3 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=./cifar10_detection/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=36, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=rtdetr-l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=rtdetr_cifar10, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/detect, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\rtdetr_cifar10, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0001, workers=2, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "WARNING no model scale passed. Assuming scale='l'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n",
      "  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n",
      "  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n",
      "  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n",
      "  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n",
      "  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n",
      "  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n",
      "  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n",
      " 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n",
      " 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n",
      " 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n",
      " 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n",
      " 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 28        [21, 24, 27]  1   7322402  ultralytics.nn.modules.head.RTDETRDecoder    [10, [256, 256, 256]]         \n",
      "rt-detr-l summary: 457 layers, 32,826,626 parameters, 32,826,626 gradients, 108.0 GFLOPs\n",
      "\n",
      "Transferred 926/941 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.35M/5.35M [00:00<00:00, 23.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 0.20.0 MB/s, size: 1.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Eric Aquino\\Documents\\RFDETR\\cifar10_detection\\labels\\train... 5000 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [00:08<00:00, 585.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\Eric Aquino\\Documents\\RFDETR\\cifar10_detection\\labels\\train.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 0.20.1 MB/s, size: 1.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Eric Aquino\\Documents\\RFDETR\\cifar10_detection\\labels\\val... 1000 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:01<00:00, 721.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Eric Aquino\\Documents\\RFDETR\\cifar10_detection\\labels\\val.cache\n",
      "Plotting labels to runs\\detect\\rtdetr_cifar10\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0001, momentum=0.937) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.0001), 226 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\rtdetr_cifar10\u001b[0m\n",
      "Starting training for 36 epochs...\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "       1/36      6.64G     0.3111      2.979     0.3687         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [04:52<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000    3.4e-05        0.1   0.000286   0.000133\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "       2/36      7.07G     0.1894      2.571     0.2261         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [04:34<00:00,  2.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000    0.00295      0.279     0.0089    0.00365\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "       3/36      6.99G     0.2092      2.138     0.2676         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [04:34<00:00,  2.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.226       0.29     0.0431      0.018\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "       4/36      7.07G     0.2601      1.513     0.3706         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [09:38<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.272      0.274     0.0751     0.0347\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "       5/36      7.06G     0.2712      1.178     0.3959         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [04:34<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.295      0.288      0.105     0.0481\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "       6/36      7.08G     0.2702      1.056     0.4056         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [04:34<00:00,  2.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.301      0.297     0.0896     0.0421\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "       7/36      7.07G      0.271      1.003     0.4067         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [20:12<00:00,  1.94s/it]    \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.418      0.331      0.176     0.0742\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "       8/36      7.06G     0.2678     0.9704     0.4015         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [04:33<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.348      0.332      0.178     0.0775\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "       9/36      7.07G     0.2697     0.9507     0.4068         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [04:34<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000       0.44      0.344      0.188     0.0891\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      10/36      7.07G     0.2669     0.9351     0.4017         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [04:33<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.406      0.406      0.259      0.124\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      11/36      6.99G     0.2679     0.9115     0.4062         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [04:34<00:00,  2.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.429      0.462      0.323      0.171\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      12/36      6.98G     0.2631     0.8973      0.398         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [04:34<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.492       0.48      0.342      0.181\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      13/36      7.07G     0.2616     0.8765     0.3977         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [23:23<00:00,  2.25s/it]   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.374      0.469      0.321      0.171\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      14/36      7.07G     0.2642     0.8528     0.4021         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [04:33<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.529      0.524       0.39      0.175\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      15/36      7.06G     0.2611     0.8424     0.3975         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [05:39<00:00,  1.84it/s]  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.422      0.515      0.402        0.2\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      16/36      6.97G     0.2618     0.8188     0.3975         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [04:34<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.479      0.555      0.441      0.239\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      17/36      6.97G     0.2633     0.7991     0.4019         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [04:36<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.557        0.6      0.492      0.266\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      18/36      6.97G     0.2615     0.7906     0.3967         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [06:53<00:00,  1.51it/s]  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.532      0.602      0.488      0.233\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      19/36      6.99G     0.2609     0.7715      0.398         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [04:45<00:00,  2.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:18<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000       0.52      0.605      0.482      0.268\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      20/36      6.98G     0.2608     0.7664     0.3985         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [06:21<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:18<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.611      0.639      0.537      0.275\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      21/36      7.07G      0.259     0.7495     0.3911         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [06:20<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:18<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.586      0.596        0.5      0.288\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      22/36      7.07G     0.2602      0.735     0.3936         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [06:20<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:18<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.599      0.639      0.538      0.271\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      23/36      7.07G     0.2591     0.7314     0.3957         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [06:18<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:18<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.622      0.656      0.561      0.313\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      24/36      6.98G     0.2584     0.7134     0.3952         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [06:19<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:18<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.621      0.662      0.569      0.335\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      25/36      7.06G     0.2597     0.7105     0.3937         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [06:20<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:18<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.671      0.664      0.597      0.328\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      26/36      7.07G     0.2588     0.6946     0.3931         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [06:19<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:18<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.655       0.66      0.594      0.333\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      27/36         7G     0.2199     0.5939     0.5063          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [06:14<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:19<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.717      0.741      0.665      0.333\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      28/36      6.98G     0.2094     0.5428     0.4688          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [05:23<00:00,  1.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.736      0.751      0.691      0.385\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      29/36      6.98G     0.2092     0.5312     0.4693          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [04:34<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.742      0.748      0.688      0.376\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      30/36      7.07G     0.2068      0.518     0.4622          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [04:34<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.763       0.77      0.708      0.414\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      31/36      7.07G     0.2054     0.5039     0.4606          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [04:34<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.752      0.768      0.708      0.416\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      32/36      7.07G     0.2062     0.5017     0.4621          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [04:33<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.764      0.781      0.722       0.43\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      33/36      7.07G     0.2042     0.4988     0.4524          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [04:34<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.769      0.781      0.724      0.424\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      34/36      7.07G     0.2033     0.4951     0.4567          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [04:34<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.769      0.784      0.726      0.433\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      35/36      6.99G     0.2024       0.49     0.4559          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [04:34<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.766      0.771      0.717      0.426\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]c:\\Users\\Eric Aquino\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      36/36      6.98G     0.2045     0.4935     0.4584          8        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [04:34<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:14<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.776      0.779       0.73      0.431\n",
      "\n",
      "36 epochs completed in 3.900 hours.\n",
      "Optimizer stripped from runs\\detect\\rtdetr_cifar10\\weights\\last.pt, 66.2MB\n",
      "Optimizer stripped from runs\\detect\\rtdetr_cifar10\\weights\\best.pt, 66.2MB\n",
      "\n",
      "Validating runs\\detect\\rtdetr_cifar10\\weights\\best.pt...\n",
      "Ultralytics 8.3.160  Python-3.13.3 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "rt-detr-l summary: 302 layers, 32,004,290 parameters, 0 gradients, 103.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:13<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000      0.766      0.786      0.725      0.434\n",
      "              airplane        103        103      0.654      0.786      0.684      0.386\n",
      "            automobile         89         89      0.863      0.933      0.915      0.549\n",
      "                  bird        100        100       0.59       0.68      0.579      0.319\n",
      "                   cat        103        103      0.672      0.477      0.393      0.244\n",
      "                  deer         90         90      0.708      0.809      0.686      0.418\n",
      "                   dog         86         86      0.781      0.674      0.619      0.386\n",
      "                  frog        112        112      0.813      0.866       0.83      0.497\n",
      "                 horse        102        102      0.847      0.824      0.801       0.49\n",
      "                  ship        106        106      0.855      0.896      0.849      0.536\n",
      "                 truck        109        109      0.872      0.917      0.892      0.511\n",
      "Speed: 0.2ms preprocess, 10.5ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\rtdetr_cifar10\u001b[0m\n",
      "‚úÖ RT-DETR training completed successfully!\n",
      "üìä Best model saved at: runs\\detect\\rtdetr_cifar10\n",
      "\n",
      "üìà Training Summary:\n",
      "  - Best mAP50: 0.7247896126473691\n",
      "  - Best mAP50-95: 0.4335725589086615\n",
      "  - Final Box Loss: N/A\n",
      "  - Final Class Loss: N/A\n",
      "  - Final DFL Loss: N/A\n",
      "\n",
      "üéØ RT-DETR Training Characteristics:\n",
      "  - Transformer architecture requires more epochs to converge\n",
      "  - Lower learning rates work better than CNN-based models\n",
      "  - AdamW optimizer is recommended for transformers\n",
      "  - Cosine learning rate scheduling helps with convergence\n",
      "  - Warmup epochs help stabilize early training\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Train RT-DETR Model\n",
    "import os\n",
    "\n",
    "print(\"üèãÔ∏è Starting RT-DETR object detection training...\")\n",
    "\n",
    "try:\n",
    "    # Train the RT-DETR model with optimized parameters\n",
    "    results = model.train(\n",
    "        data=dataset.data_yaml,     # Path to dataset YAML file\n",
    "        epochs=36,                  # Number of training epochs\n",
    "        imgsz=640,                  # Input image size (RT-DETR standard)\n",
    "        batch=8,                    # Batch size (adjust based on GPU memory)\n",
    "        lr0=0.0001,                 # Initial learning rate (lower for transformers)\n",
    "        weight_decay=0.0001,        # Weight decay for regularization\n",
    "        patience=10,                # Early stopping patience\n",
    "        save=True,                  # Save checkpoints\n",
    "        plots=True,                 # Generate training plots\n",
    "        verbose=True,               # Verbose output\n",
    "        workers=2,                  # Number of worker threads\n",
    "        project='runs/detect',      # Project directory\n",
    "        name='rtdetr_cifar10',      # Experiment name\n",
    "        exist_ok=True,              # Overwrite existing experiment\n",
    "        pretrained=True,            # Use pretrained weights\n",
    "        optimizer='AdamW',          # Optimizer (AdamW works well with transformers)\n",
    "        cos_lr=True,                # Cosine learning rate scheduler\n",
    "        warmup_epochs=3,            # Warmup epochs\n",
    "        warmup_momentum=0.8,        # Warmup momentum\n",
    "        box=7.5,                    # Box loss gain\n",
    "        cls=0.5,                    # Classification loss gain\n",
    "        dfl=1.5,                    # Distribution focal loss gain\n",
    "    )\n",
    "\n",
    "    print(\"‚úÖ RT-DETR training completed successfully!\")\n",
    "    print(f\"üìä Best model saved at: {results.save_dir}\")\n",
    "\n",
    "    # Display training summary\n",
    "    if hasattr(results, 'results_dict'):\n",
    "        print(\"\\nüìà Training Summary:\")\n",
    "        metrics = results.results_dict\n",
    "        print(f\"  - Best mAP50: {metrics.get('metrics/mAP50(B)', 'N/A')}\")\n",
    "        print(f\"  - Best mAP50-95: {metrics.get('metrics/mAP50-95(B)', 'N/A')}\")\n",
    "        print(f\"  - Final Box Loss: {metrics.get('train/box_loss', 'N/A')}\")\n",
    "        print(f\"  - Final Class Loss: {metrics.get('train/cls_loss', 'N/A')}\")\n",
    "        print(f\"  - Final DFL Loss: {metrics.get('train/dfl_loss', 'N/A')}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Training failed: {e}\")\n",
    "    print(\"üí° Troubleshooting tips:\")\n",
    "    print(\"  - Try reducing batch size (batch=4 or batch=2)\")\n",
    "    print(\"  - Try reducing epochs (epochs=10)\")\n",
    "    print(\"  - Ensure CUDA is available for GPU training\")\n",
    "    print(\"  - Check if the dataset YAML file is correct\")\n",
    "\n",
    "    # Alternative: Try with reduced parameters\n",
    "    print(\"\\nüîÑ Trying with reduced parameters...\")\n",
    "    try:\n",
    "        results = model.train(\n",
    "            data=dataset.data_yaml,\n",
    "            epochs=36,              # Reduced epochs\n",
    "            imgsz=320,              # Smaller image size\n",
    "            batch=4,                # Smaller batch size\n",
    "            lr0=0.0001,\n",
    "            patience=5,\n",
    "            project='runs/detect',\n",
    "            name='rtdetr_cifar10_reduced',\n",
    "            exist_ok=True\n",
    "        )\n",
    "        print(\"‚úÖ Reduced training completed!\")\n",
    "    except Exception as e2:\n",
    "        print(f\"‚ùå Reduced training also failed: {e2}\")\n",
    "        print(\"üí° Consider using a pre-trained model for inference instead\")\n",
    "\n",
    "# Additional training information\n",
    "print(f\"\\nüéØ RT-DETR Training Characteristics:\")\n",
    "print(\"  - Transformer architecture requires more epochs to converge\")\n",
    "print(\"  - Lower learning rates work better than CNN-based models\")\n",
    "print(\"  - AdamW optimizer is recommended for transformers\")\n",
    "print(\"  - Cosine learning rate scheduling helps with convergence\")\n",
    "print(\"  - Warmup epochs help stabilize early training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "502ddbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluating RT-DETR object detection performance...\n",
      "Ultralytics 8.3.160  Python-3.13.3 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "rt-detr-l summary: 302 layers, 32,004,290 parameters, 0 gradients, 103.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 29.311.5 MB/s, size: 1.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Eric Aquino\\Documents\\RFDETR\\cifar10_detection\\labels\\val.cache... 1000 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:22<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1000       1000       0.75      0.782       0.79      0.496\n",
      "              airplane        103        103      0.594      0.796      0.737      0.432\n",
      "            automobile         89         89      0.856      0.933      0.936      0.588\n",
      "                  bird        100        100      0.607       0.68      0.676      0.391\n",
      "                   cat        103        103      0.681      0.456      0.532      0.355\n",
      "                  deer         90         90      0.657      0.789      0.729      0.469\n",
      "                   dog         86         86      0.787      0.686      0.745       0.49\n",
      "                  frog        112        112      0.817      0.875      0.888      0.551\n",
      "                 horse        102        102      0.835      0.794      0.846      0.546\n",
      "                  ship        106        106      0.841      0.896      0.887      0.584\n",
      "                 truck        109        109      0.826      0.917       0.92      0.552\n",
      "Speed: 0.2ms preprocess, 19.9ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Saving runs\\detect\\rtdetr_cifar10\\predictions.json...\n",
      "Results saved to \u001b[1mruns\\detect\\rtdetr_cifar10\u001b[0m\n",
      "\n",
      "üìà Object Detection Results:\n",
      "  - mAP50: 0.790\n",
      "  - mAP50-95: 0.496\n",
      "  - Precision: 0.750\n",
      "  - Recall: 0.782\n",
      "  - mAP50 (all classes): [    0.43172     0.58834     0.39052     0.35484      0.4694     0.49044     0.55105     0.54642     0.58422      0.5524]\n",
      "\n",
      "üìä Detailed Metrics:\n",
      "  - Box Precision: 0.7501121811802218\n",
      "  - Box Recall: 0.782272210945945\n",
      "  - mAP50: 0.7896636659799252\n",
      "  - mAP50-95: 0.4959353729709012\n",
      "\n",
      "üìä Training plots saved in: runs/detect/rtdetr_cifar10/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ RT-DETR Performance Notes:\n",
      "  - mAP50: Mean Average Precision at IoU threshold 0.5\n",
      "  - mAP50-95: Mean Average Precision averaged over IoU thresholds 0.5-0.95\n",
      "  - Precision: TP / (TP + FP) - How many detections were correct\n",
      "  - Recall: TP / (TP + FN) - How many objects were detected\n",
      "  - Good mAP50 for CIFAR-10: > 0.7\n",
      "  - Good mAP50-95 for CIFAR-10: > 0.4\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: RT-DETR Model Evaluation\n",
    "print(\"üìä Evaluating RT-DETR object detection performance...\")\n",
    "\n",
    "try:\n",
    "    # Validate the model on the validation set\n",
    "    validation_results = model.val(\n",
    "        data=dataset.data_yaml,\n",
    "        split='val',\n",
    "        plots=True,\n",
    "        save_json=True,\n",
    "        conf=0.25,              # Confidence threshold\n",
    "        iou=0.6,                # IoU threshold for NMS\n",
    "        max_det=100,            # Maximum detections per image\n",
    "        half=False,             # Use FP16 inference\n",
    "        device='',              # Auto-select device\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    # Display key metrics for object detection\n",
    "    print(\"\\nüìà Object Detection Results:\")\n",
    "\n",
    "    # Access box metrics\n",
    "    if hasattr(validation_results, 'box'):\n",
    "        box_metrics = validation_results.box\n",
    "        print(f\"  - mAP50: {box_metrics.map50:.3f}\")\n",
    "        print(f\"  - mAP50-95: {box_metrics.map:.3f}\")\n",
    "        print(f\"  - Precision: {box_metrics.mp:.3f}\")\n",
    "        print(f\"  - Recall: {box_metrics.mr:.3f}\")\n",
    "        print(f\"  - mAP50 (all classes): {box_metrics.maps}\")\n",
    "\n",
    "    # Alternative way to access metrics\n",
    "    if hasattr(validation_results, 'results_dict'):\n",
    "        metrics = validation_results.results_dict\n",
    "        print(f\"\\nüìä Detailed Metrics:\")\n",
    "        print(f\"  - Box Precision: {metrics.get('metrics/precision(B)', 'N/A')}\")\n",
    "        print(f\"  - Box Recall: {metrics.get('metrics/recall(B)', 'N/A')}\")\n",
    "        print(f\"  - mAP50: {metrics.get('metrics/mAP50(B)', 'N/A')}\")\n",
    "        print(f\"  - mAP50-95: {metrics.get('metrics/mAP50-95(B)', 'N/A')}\")\n",
    "\n",
    "    # Plot training results if available\n",
    "    import matplotlib.pyplot as plt\n",
    "    import glob\n",
    "\n",
    "    # Look for training plots\n",
    "    plot_files = glob.glob(os.path.join('runs/detect/rtdetr_cifar10*', '*.png'))\n",
    "\n",
    "    if plot_files:\n",
    "        print(f\"\\nüìä Training plots saved in: runs/detect/rtdetr_cifar10/\")\n",
    "\n",
    "        # Display results plot\n",
    "        results_plot = [f for f in plot_files if 'results.png' in f]\n",
    "        if results_plot:\n",
    "            img = plt.imread(results_plot[0])\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.title('RT-DETR Training Results')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # Display confusion matrix\n",
    "        confusion_plot = [f for f in plot_files if 'confusion_matrix.png' in f]\n",
    "        if confusion_plot:\n",
    "            img = plt.imread(confusion_plot[0])\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.title('RT-DETR Confusion Matrix')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # Display PR curve\n",
    "        pr_curve_plot = [f for f in plot_files if 'PR_curve.png' in f]\n",
    "        if pr_curve_plot:\n",
    "            img = plt.imread(pr_curve_plot[0])\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.title('Precision-Recall Curve')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # Display F1 curve\n",
    "        f1_curve_plot = [f for f in plot_files if 'F1_curve.png' in f]\n",
    "        if f1_curve_plot:\n",
    "            img = plt.imread(f1_curve_plot[0])\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.title('F1-Confidence Curve')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Evaluation error: {e}\")\n",
    "    print(\"Continuing with manual evaluation...\")\n",
    "\n",
    "    # Manual evaluation using validation images\n",
    "    print(\"\\nüîÑ Performing manual evaluation...\")\n",
    "    try:\n",
    "        val_images_dir = f\"{dataset.location}/images/val\"\n",
    "        val_images = [f for f in os.listdir(val_images_dir) if f.endswith('.jpg')][:10]\n",
    "\n",
    "        correct_detections = 0\n",
    "        total_detections = 0\n",
    "\n",
    "        for img_file in val_images:\n",
    "            img_path = os.path.join(val_images_dir, img_file)\n",
    "\n",
    "            # Run detection\n",
    "            results = model(img_path, conf=0.25, verbose=False)\n",
    "\n",
    "            if results and len(results) > 0:\n",
    "                result = results[0]\n",
    "\n",
    "                # Count detections\n",
    "                if result.boxes is not None:\n",
    "                    num_detections = len(result.boxes)\n",
    "                    total_detections += num_detections\n",
    "\n",
    "                    # For CIFAR-10, we expect exactly 1 detection per image\n",
    "                    if num_detections == 1:\n",
    "                        correct_detections += 1\n",
    "\n",
    "        if total_detections > 0:\n",
    "            detection_accuracy = correct_detections / len(val_images)\n",
    "            avg_detections = total_detections / len(val_images)\n",
    "            print(f\"üìä Manual evaluation results:\")\n",
    "            print(f\"  - Images with correct detection count: {correct_detections}/{len(val_images)} ({detection_accuracy:.3f})\")\n",
    "            print(f\"  - Average detections per image: {avg_detections:.2f}\")\n",
    "\n",
    "    except Exception as eval_error:\n",
    "        print(f\"‚ùå Manual evaluation failed: {eval_error}\")\n",
    "\n",
    "print(f\"\\nüéØ RT-DETR Performance Notes:\")\n",
    "print(\"  - mAP50: Mean Average Precision at IoU threshold 0.5\")\n",
    "print(\"  - mAP50-95: Mean Average Precision averaged over IoU thresholds 0.5-0.95\")\n",
    "print(\"  - Precision: TP / (TP + FP) - How many detections were correct\")\n",
    "print(\"  - Recall: TP / (TP + FN) - How many objects were detected\")\n",
    "print(\"  - Good mAP50 for CIFAR-10: > 0.7\")\n",
    "print(\"  - Good mAP50-95 for CIFAR-10: > 0.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "852dc0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñºÔ∏è Running RT-DETR object detection inference and visualization...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1200 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Detection Analysis:\n",
      "  ‚úÖ val_img_00913.jpg: True=deer, Pred=deer (0.862)\n",
      "  ‚úÖ val_img_00929.jpg: True=airplane, Pred=airplane (0.844)\n",
      "  ‚úÖ val_img_00223.jpg: True=deer, Pred=deer (0.702)\n",
      "  ‚úÖ val_img_00516.jpg: True=ship, Pred=ship (0.881)\n",
      "  ‚úÖ val_img_00142.jpg: True=frog, Pred=frog (0.853)\n",
      "  ‚úÖ val_img_00288.jpg: True=horse, Pred=horse (0.572)\n",
      "\n",
      "üìä Detection Summary:\n",
      "  - Total images: 6\n",
      "  - Images with detections: 6\n",
      "  - Correct class detections: 6\n",
      "  - No detections: 0\n",
      "  - Detection rate: 1.000\n",
      "  - Classification accuracy: 1.000\n",
      "\n",
      "üìà Detected Classes Distribution:\n",
      "  - deer: 2 detections\n",
      "  - airplane: 1 detections\n",
      "  - ship: 1 detections\n",
      "  - frog: 1 detections\n",
      "  - horse: 1 detections\n"
     ]
    }
   ],
   "source": [
    "# STEP 6: Visualize RT-DETR Object Detection Predictions\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "print(\"üñºÔ∏è Running RT-DETR object detection inference and visualization...\")\n",
    "\n",
    "def visualize_detection_predictions(image_path, model, conf_threshold=0.25, iou_threshold=0.6):\n",
    "    \"\"\"Run object detection inference and return results\"\"\"\n",
    "    try:\n",
    "        # Run prediction\n",
    "        results = model(\n",
    "            image_path,\n",
    "            conf=conf_threshold,\n",
    "            iou=iou_threshold,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        if results and len(results) > 0:\n",
    "            result = results[0]\n",
    "\n",
    "            # Get annotated image\n",
    "            annotated_img = result.plot(\n",
    "                line_width=2,\n",
    "                font_size=12,\n",
    "                font='Arial.ttf',\n",
    "                pil=False,  # Return as numpy array\n",
    "                img=None,\n",
    "                labels=True,\n",
    "                boxes=True,\n",
    "                conf=True\n",
    "            )\n",
    "\n",
    "            # Convert BGR to RGB for matplotlib\n",
    "            if annotated_img is not None:\n",
    "                annotated_img_rgb = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)\n",
    "            else:\n",
    "                annotated_img_rgb = None\n",
    "\n",
    "            return annotated_img_rgb, result\n",
    "        else:\n",
    "            return None, None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Detection error: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Get validation images\n",
    "val_images_dir = os.path.join(dataset.location, \"images\", \"val\")\n",
    "val_labels_dir = os.path.join(dataset.location, \"labels\", \"val\")\n",
    "\n",
    "if not os.path.exists(val_images_dir):\n",
    "    print(f\"‚ùå Validation directory not found: {val_images_dir}\")\n",
    "else:\n",
    "    image_files = [f for f in os.listdir(val_images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "    if not image_files:\n",
    "        print(\"‚ùå No images found in validation directory\")\n",
    "    else:\n",
    "        # Select 6 random images for visualization\n",
    "        sample_images = random.sample(image_files, min(6, len(image_files)))\n",
    "\n",
    "        plt.figure(figsize=(18, 12))\n",
    "\n",
    "        detection_results = []\n",
    "\n",
    "        for i, img_file in enumerate(sample_images):\n",
    "            image_path = os.path.join(val_images_dir, img_file)\n",
    "\n",
    "            # Load original image for display\n",
    "            original_img = Image.open(image_path)\n",
    "\n",
    "            # Get ground truth from label file\n",
    "            label_file = img_file.replace('.jpg', '.txt').replace('.jpeg', '.txt').replace('.png', '.txt')\n",
    "            label_path = os.path.join(val_labels_dir, label_file)\n",
    "\n",
    "            true_class = \"unknown\"\n",
    "            if os.path.exists(label_path):\n",
    "                with open(label_path, 'r') as f:\n",
    "                    label_line = f.readline().strip()\n",
    "                    if label_line:\n",
    "                        class_id = int(label_line.split()[0])\n",
    "                        true_class = cifar10_classes[class_id]\n",
    "\n",
    "            # Run detection\n",
    "            annotated_img, result = visualize_detection_predictions(image_path, model, conf_threshold=0.25)\n",
    "\n",
    "            # Plot original image\n",
    "            plt.subplot(2, 6, i+1)\n",
    "            plt.imshow(original_img)\n",
    "            plt.axis('off')\n",
    "            plt.title(f'Original\\nTrue: {true_class}', fontsize=10)\n",
    "\n",
    "            # Plot detection result\n",
    "            plt.subplot(2, 6, i+7)\n",
    "            if annotated_img is not None:\n",
    "                plt.imshow(annotated_img)\n",
    "                plt.axis('off')\n",
    "\n",
    "                # Extract detection info\n",
    "                detections_info = []\n",
    "                if result.boxes is not None and len(result.boxes) > 0:\n",
    "                    for j in range(len(result.boxes)):\n",
    "                        conf = result.boxes.conf[j].item()\n",
    "                        cls_id = int(result.boxes.cls[j].item())\n",
    "                        pred_class = result.names[cls_id]\n",
    "                        detections_info.append(f\"{pred_class} ({conf:.2f})\")\n",
    "\n",
    "                    title = f\"RT-DETR Detection\\n\" + \"\\n\".join(detections_info[:2])  # Show max 2 detections\n",
    "\n",
    "                    # Color code based on accuracy\n",
    "                    color = 'green' if any(true_class in det for det in detections_info) else 'red'\n",
    "                    plt.title(title, fontsize=9, color=color)\n",
    "                else:\n",
    "                    plt.title(\"RT-DETR Detection\\nNo objects detected\", fontsize=9, color='red')\n",
    "            else:\n",
    "                plt.imshow(original_img)\n",
    "                plt.axis('off')\n",
    "                plt.title(\"Detection Failed\", fontsize=9, color='red')\n",
    "\n",
    "            # Store results for analysis\n",
    "            detection_results.append({\n",
    "                'image': img_file,\n",
    "                'true_class': true_class,\n",
    "                'result': result\n",
    "            })\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.suptitle('RT-DETR Object Detection Results on CIFAR-10', fontsize=16, y=0.98)\n",
    "        plt.show()\n",
    "\n",
    "        # Analyze detection results\n",
    "        print(f\"\\nüîç Detection Analysis:\")\n",
    "        correct_class_detections = 0\n",
    "        total_detections = 0\n",
    "        no_detection_count = 0\n",
    "\n",
    "        for res in detection_results:\n",
    "            result = res['result']\n",
    "            true_class = res['true_class']\n",
    "\n",
    "            if result and result.boxes is not None and len(result.boxes) > 0:\n",
    "                # Get the most confident detection\n",
    "                max_conf_idx = result.boxes.conf.argmax()\n",
    "                pred_class_id = int(result.boxes.cls[max_conf_idx].item())\n",
    "                pred_class = result.names[pred_class_id]\n",
    "                confidence = result.boxes.conf[max_conf_idx].item()\n",
    "\n",
    "                status = \"‚úÖ\" if pred_class == true_class else \"‚ùå\"\n",
    "                print(f\"  {status} {res['image']}: True={true_class}, Pred={pred_class} ({confidence:.3f})\")\n",
    "\n",
    "                if pred_class == true_class:\n",
    "                    correct_class_detections += 1\n",
    "                total_detections += 1\n",
    "            else:\n",
    "                print(f\"  ‚ö™ {res['image']}: True={true_class}, No detection\")\n",
    "                no_detection_count += 1\n",
    "\n",
    "        # Summary statistics\n",
    "        total_images = len(detection_results)\n",
    "        class_accuracy = correct_class_detections / total_images if total_images > 0 else 0\n",
    "        detection_rate = total_detections / total_images if total_images > 0 else 0\n",
    "\n",
    "        print(f\"\\nüìä Detection Summary:\")\n",
    "        print(f\"  - Total images: {total_images}\")\n",
    "        print(f\"  - Images with detections: {total_detections}\")\n",
    "        print(f\"  - Correct class detections: {correct_class_detections}\")\n",
    "        print(f\"  - No detections: {no_detection_count}\")\n",
    "        print(f\"  - Detection rate: {detection_rate:.3f}\")\n",
    "        print(f\"  - Classification accuracy: {class_accuracy:.3f}\")\n",
    "\n",
    "        # Class distribution analysis\n",
    "        detected_classes = {}\n",
    "        for res in detection_results:\n",
    "            result = res['result']\n",
    "            if result and result.boxes is not None and len(result.boxes) > 0:\n",
    "                for j in range(len(result.boxes)):\n",
    "                    cls_id = int(result.boxes.cls[j].item())\n",
    "                    pred_class = result.names[cls_id]\n",
    "                    detected_classes[pred_class] = detected_classes.get(pred_class, 0) + 1\n",
    "\n",
    "        if detected_classes:\n",
    "            print(f\"\\nüìà Detected Classes Distribution:\")\n",
    "            for class_name, count in detected_classes.items():\n",
    "                print(f\"  - {class_name}: {count} detections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15421caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Example: Running batch detection on validation set...\n",
      "üì¶ Created sample with 20 images\n",
      "üöÄ Running batch RT-DETR object detection inference...\n",
      "üìä Processing 40 images...\n",
      "\n",
      "‚úÖ Batch RT-DETR detection completed!\n",
      "‚è±Ô∏è Processing time: 1.23 seconds\n",
      "üìä Total images processed: 40\n",
      "üìÅ Results saved in: ./detection_results\n",
      "‚ö° Average: 32.4 images/second\n",
      "üéØ Total detections: 44\n",
      "üîç Images with detections: 40/40 (100.0%)\n",
      "\n",
      "üìä Detected Class Distribution (conf >= 0.25):\n",
      "  - airplane: 6 (13.6%)\n",
      "  - automobile: 6 (13.6%)\n",
      "  - cat: 4 (9.1%)\n",
      "  - deer: 2 (4.5%)\n",
      "  - dog: 2 (4.5%)\n",
      "  - frog: 10 (22.7%)\n",
      "  - horse: 4 (9.1%)\n",
      "  - ship: 6 (13.6%)\n",
      "  - truck: 4 (9.1%)\n",
      "\n",
      "üìà Additional Statistics:\n",
      "  - Average detections per image: 1.10\n",
      "  - Maximum detections in single image: 2\n"
     ]
    }
   ],
   "source": [
    "# STEP 7: Batch RT-DETR Object Detection Inference\n",
    "import time\n",
    "from pathlib import Path\n",
    "import json\n",
    "import csv\n",
    "\n",
    "def run_batch_detection(input_dir, output_dir, conf_threshold=0.25, iou_threshold=0.6):\n",
    "    \"\"\"Run RT-DETR object detection inference on all images in a directory\"\"\"\n",
    "    print(f\"üöÄ Running batch RT-DETR object detection inference...\")\n",
    "\n",
    "    # Create output directory\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Get all image files\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
    "    image_files = []\n",
    "    for ext in image_extensions:\n",
    "        image_files.extend(Path(input_dir).glob(f'**/*{ext}'))  # Recursive search\n",
    "        image_files.extend(Path(input_dir).glob(f'**/*{ext.upper()}'))\n",
    "\n",
    "    if not image_files:\n",
    "        print(f\"‚ùå No images found in {input_dir}\")\n",
    "        return\n",
    "\n",
    "    print(f\"üìä Processing {len(image_files)} images...\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    results_data = []\n",
    "    class_counts = {class_name: 0 for class_name in cifar10_classes}\n",
    "    total_detections = 0\n",
    "\n",
    "    # Process images\n",
    "    for i, image_path in enumerate(image_files):\n",
    "        try:\n",
    "            # Run RT-DETR detection\n",
    "            results = model(\n",
    "                str(image_path),\n",
    "                conf=conf_threshold,\n",
    "                iou=iou_threshold,\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            if results and len(results) > 0:\n",
    "                result = results[0]\n",
    "\n",
    "                # Process detections\n",
    "                detections = []\n",
    "                if result.boxes is not None and len(result.boxes) > 0:\n",
    "                    for j in range(len(result.boxes)):\n",
    "                        # Get detection info\n",
    "                        box = result.boxes.xyxy[j].cpu().numpy()  # [x1, y1, x2, y2]\n",
    "                        conf = result.boxes.conf[j].item()\n",
    "                        cls_id = int(result.boxes.cls[j].item())\n",
    "                        class_name = result.names[cls_id]\n",
    "\n",
    "                        detection = {\n",
    "                            'bbox': box.tolist(),\n",
    "                            'confidence': conf,\n",
    "                            'class_id': cls_id,\n",
    "                            'class_name': class_name\n",
    "                        }\n",
    "                        detections.append(detection)\n",
    "\n",
    "                        # Count classes\n",
    "                        class_counts[class_name] += 1\n",
    "                        total_detections += 1\n",
    "\n",
    "                # Store image results\n",
    "                result_entry = {\n",
    "                    'image_path': str(image_path),\n",
    "                    'image_name': image_path.name,\n",
    "                    'num_detections': len(detections),\n",
    "                    'detections': detections\n",
    "                }\n",
    "\n",
    "                # Try to extract true class from directory structure or filename\n",
    "                parent_dir = image_path.parent.name\n",
    "                if parent_dir in cifar10_classes:\n",
    "                    result_entry['true_class'] = parent_dir\n",
    "\n",
    "                    # Check if correct class was detected\n",
    "                    detected_classes = [det['class_name'] for det in detections]\n",
    "                    result_entry['correct_detection'] = parent_dir in detected_classes\n",
    "\n",
    "                    # Find best detection for this true class\n",
    "                    matching_detections = [det for det in detections if det['class_name'] == parent_dir]\n",
    "                    if matching_detections:\n",
    "                        best_detection = max(matching_detections, key=lambda x: x['confidence'])\n",
    "                        result_entry['best_confidence'] = best_detection['confidence']\n",
    "\n",
    "                results_data.append(result_entry)\n",
    "\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Failed to process {image_path.name}\")\n",
    "                results_data.append({\n",
    "                    'image_path': str(image_path),\n",
    "                    'image_name': image_path.name,\n",
    "                    'num_detections': 0,\n",
    "                    'detections': [],\n",
    "                    'error': 'Detection failed'\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {image_path.name}: {e}\")\n",
    "            results_data.append({\n",
    "                'image_path': str(image_path),\n",
    "                'image_name': image_path.name,\n",
    "                'num_detections': 0,\n",
    "                'detections': [],\n",
    "                'error': str(e)\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # Progress update\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"  Processed {i + 1}/{len(image_files)} images...\")\n",
    "\n",
    "    processing_time = time.time() - start_time\n",
    "\n",
    "    # Save results to files\n",
    "    results_json_path = Path(output_dir) / 'detection_results.json'\n",
    "    results_csv_path = Path(output_dir) / 'detection_summary.csv'\n",
    "\n",
    "    # Save detailed JSON results\n",
    "    with open(results_json_path, 'w') as f:\n",
    "        json.dump(results_data, f, indent=2)\n",
    "\n",
    "    # Create CSV summary\n",
    "    csv_data = []\n",
    "    for result in results_data:\n",
    "        csv_row = {\n",
    "            'image_name': result['image_name'],\n",
    "            'num_detections': result['num_detections'],\n",
    "            'true_class': result.get('true_class', 'unknown'),\n",
    "            'correct_detection': result.get('correct_detection', False),\n",
    "            'best_confidence': result.get('best_confidence', 0.0),\n",
    "            'error': result.get('error', '')\n",
    "        }\n",
    "\n",
    "        # Add top detection info\n",
    "        if result['detections']:\n",
    "            top_detection = max(result['detections'], key=lambda x: x['confidence'])\n",
    "            csv_row.update({\n",
    "                'top_class': top_detection['class_name'],\n",
    "                'top_confidence': top_detection['confidence']\n",
    "            })\n",
    "        else:\n",
    "            csv_row.update({\n",
    "                'top_class': '',\n",
    "                'top_confidence': 0.0\n",
    "            })\n",
    "\n",
    "        csv_data.append(csv_row)\n",
    "\n",
    "    # Save CSV\n",
    "    if csv_data:\n",
    "        with open(results_csv_path, 'w', newline='') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=csv_data[0].keys())\n",
    "            writer.writeheader()\n",
    "            writer.writerows(csv_data)\n",
    "\n",
    "    # Calculate metrics\n",
    "    correct_detections = sum(1 for r in results_data if r.get('correct_detection', False))\n",
    "    total_with_labels = sum(1 for r in results_data if 'true_class' in r)\n",
    "    images_with_detections = sum(1 for r in results_data if r['num_detections'] > 0)\n",
    "\n",
    "    print(f\"\\n‚úÖ Batch RT-DETR detection completed!\")\n",
    "    print(f\"‚è±Ô∏è Processing time: {processing_time:.2f} seconds\")\n",
    "    print(f\"üìä Total images processed: {len(results_data)}\")\n",
    "    print(f\"üìÅ Results saved in: {output_dir}\")\n",
    "    print(f\"‚ö° Average: {len(image_files)/processing_time:.1f} images/second\")\n",
    "    print(f\"üéØ Total detections: {total_detections}\")\n",
    "    print(f\"üîç Images with detections: {images_with_detections}/{len(results_data)} ({images_with_detections/len(results_data)*100:.1f}%)\")\n",
    "\n",
    "    if total_with_labels > 0:\n",
    "        accuracy = correct_detections / total_with_labels\n",
    "        print(f\"üìà Classification accuracy: {accuracy:.3f} ({correct_detections}/{total_with_labels})\")\n",
    "\n",
    "    # Show class distribution\n",
    "    print(f\"\\nüìä Detected Class Distribution (conf >= {conf_threshold}):\")\n",
    "    for class_name, count in class_counts.items():\n",
    "        if count > 0:\n",
    "            percentage = (count / total_detections) * 100 if total_detections > 0 else 0\n",
    "            print(f\"  - {class_name}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "    return results_data\n",
    "\n",
    "# Example usage - detect objects in validation images\n",
    "print(\"üéØ Example: Running batch detection on validation set...\")\n",
    "\n",
    "# Run on a subset of validation data\n",
    "val_dir = os.path.join(dataset.location, \"images\", \"val\")\n",
    "if os.path.exists(val_dir):\n",
    "    # Create a smaller sample for demonstration\n",
    "    sample_dir = \"./temp_detection_sample\"\n",
    "    os.makedirs(sample_dir, exist_ok=True)\n",
    "\n",
    "    # Copy a few images from validation set\n",
    "    import shutil\n",
    "    val_images = [f for f in os.listdir(val_dir) if f.endswith('.jpg')][:20]  # Sample 20 images\n",
    "\n",
    "    sample_count = 0\n",
    "    for img in val_images:\n",
    "        try:\n",
    "            shutil.copy2(\n",
    "                os.path.join(val_dir, img),\n",
    "                os.path.join(sample_dir, img)\n",
    "            )\n",
    "            sample_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error copying {img}: {e}\")\n",
    "\n",
    "    if sample_count > 0:\n",
    "        print(f\"üì¶ Created sample with {sample_count} images\")\n",
    "        results = run_batch_detection(\n",
    "            input_dir=sample_dir,\n",
    "            output_dir=\"./detection_results\",\n",
    "            conf_threshold=0.25,\n",
    "            iou_threshold=0.6\n",
    "        )\n",
    "\n",
    "        # Clean up sample directory\n",
    "        shutil.rmtree(sample_dir)\n",
    "\n",
    "        # Show some statistics\n",
    "        if results:\n",
    "            avg_detections = sum(r['num_detections'] for r in results) / len(results)\n",
    "            max_detections = max(r['num_detections'] for r in results)\n",
    "            print(f\"\\nüìà Additional Statistics:\")\n",
    "            print(f\"  - Average detections per image: {avg_detections:.2f}\")\n",
    "            print(f\"  - Maximum detections in single image: {max_detections}\")\n",
    "    else:\n",
    "        print(\"‚ùå No sample images created for batch processing\")\n",
    "else:\n",
    "    print(\"‚ùå Validation directory not found\")\n",
    "\n",
    "# Uncomment below to run on full validation set\n",
    "# run_batch_detection(\n",
    "#     input_dir=os.path.join(dataset.location, \"images\", \"val\"),\n",
    "#     output_dir=\"./full_detection_results\",\n",
    "#     conf_threshold=0.25,\n",
    "#     iou_threshold=0.6\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad96c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
